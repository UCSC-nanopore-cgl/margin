# Toil MarginPhase #

This is a Toil workflow designed to run MarginPhase by chunking an input BAM, running MarginPhase on each chunk in parallel, and then merging the output.

## Using Toil MarginPhase ##

### Docker Initialization ###

The Toil script needs a docker image with the marginPhase excecutable to run.

#### Quick Start ####

```
cd marginPhase/toil/docker
make
```

#### Under the Hood ####
So that the identifier used to tag the docker image matches the marginPhase repository's commit hash, the docker image creator copies the current repository into the docker image instead of checking it out from github.  This means that any differences between the current code and what's in the repository will be included (and perhaps be undocumented) in the docker image.

It is recommended that you only publish docker images which were created from an unmodified repository.

### Toil ###

#### Requirements ###

* Python2.7
    * pip
    * virtualenv
* Docker

#### Quick Start ####

```
# environment prep
cd marginPhase/toil
virtualenv venv
. venv/bin/activate
make prepare
make develop

# toil prep
toil-marginphase generate
vim manifest-toil-marginphase.tsv
vim config-toil-marginphase.yaml

# run toil-marginphase
toil-marginphase run --workDir /your/work/directory /your/jobstore/directory
# ..or:
time toil-marginphase run --workDir /your/work/directory /your/jobstore/directory 2>&amp;1 | tee -a toil-marginPhase.log
```

#### Configuration ###

The default config and manifest file (created by running 'toil-marginphase generate') need to be modified to fit the marginPhase run.  The files generated give descriptions of the values and requirements.

Each sample needs a unique UUID and sample location (and must be from a single contig).  Each sample also needs a reference FASTA, a marginPhase parameters file, and must have the contig name specified.  If all samples in a run share any of these, default values can be specified in the configuration (this is optional).  If a reference FASTA, params file, and/or contig name are specified in the manifest, that value will be used during the run.

#### Output ####

The output for a sample is compressed in a tarball.  This tarball contains all output from each chunk's marginPhase run, two SAM files and a VCF for each merged chunk, and a single VCF created by merging the output from all chunks.

The output from each chunk's marginPhase run includes all standard output (notably the two haplotype SAM files and the VCF), the log of the run's output, and the input BAM.

The output tarball is named $UUID.tar.gz, the marginPhase output is named $UUID.$CHUNK_IDX.out.* (input BAM is named $UUID.$CHUNK_IDX.in.bam), the merged output is named $UUID.merged.$MERGE_IDX.*, and the VCF generated by merging all output VCFs is named $UUID.merged.full.vcf.

## Chunking Algorithm ##

### Introduction ###

The idea here is that it is prohibitively memory-intensive to run marginPhase on chromosome-scale BAMs.  So we break apart the BAMs into smaller (manageable) chunks and run marginPhase on these in parallel.  Then the output of these is stitched back together to get an approximation of the true result.

This process requires these parameters:
1. CHUNK_SIZE: Size of the chunk
1. CHUNK_MARGIN: The distance on each side of the chunks boundaries to include. This is for forcing overlap, and is used in stitching chunks back together
1. MERGE_RATIO: This value (.5, 1] is used to determine whether two adjacent chunks should be merged

### Dividing into Chunks ###

1. Get the range of reference positions covered by the reads.
    * To find this we inspect the position of the first and last read in the sorted BAM file
    * Def: START_POS, END_POS
1. Find chunk boundaries.
    * Def: CHUNKS = []
    * CHUNK_START = START_POS
    * CHUNK_END = CHUNK_START + CHUNK_SIZE
    * CHUNK = (CHUNK_START - CHUNK_MARGIN, CHUNK_END + CHUNK_MARGIN)
    * CHUNKS.append(CHUNK)
    * CHUNK_START = CHUNK_END
    * Iterate until CHUNK_END > END_POS
1. Divide BAM into chunks
    * We use a Samtools docker image for this.
    * This means that all reads which cover the ends of the chunk (with the margins for overlap) are included in each chunk.  So there would still be read overlap across adjacent chunks if CHUNK_MARGIN was 0.
    * Any chunk which has no reads is discarded

Once chunks have been divided, marginPhase is run on each chunk.  The output (of significance) of this is a bipartition of reads into two SAM files (Haplotype1 and Haplotype2) and a phased VCF where the left phase refers to calls made in Haplotype1 and the right phase refers to calls from Haplotype2.

### Merging Chunks ###

While merging chunks, our goal is to find which adjacent chunks should be merged together (all chunks which qualify are merged together), and which ones shouldn't.  When there is not evidence that adjacent chunks have overlap, a new "merged chunk" is created.  For each set of chunks which should be merged, a pair of SAM files and a single VCF is outputted.  Additionally, the output includes a single VCF is which contains the calls from all chunks, whether or not the chunks were merged.

1. Initialize
    * PREV_HAP1_READS, PREV_HAP2_READS are initialized to empty sets.  These are the reads which exist in the boundary overlap positions
    * Sort CHUNKS by start position
    * For each chunk, CHUNK_START and CHUNK_END denote the boundaries of the chunk (and do not include CHUNK_MARGIN)
1. For each CHUNK in CHUNKS
    1. Get read IDs
        * CURR_HAP1_READS = {all read IDs which are between CHUNK_START-CHUNK_MARGIN and CHUNK_START+CHUNK_MARGIN for the chunks Haplotype1 SAM file}
        * CURR_HAP2_READS = {same, except for the chunk's Haplotype2 SAM file}
    1. Determine read counts
        * PREV1_CURR1_COUNT = | PREV_HAP1_READS intersection CURR_HAP1_READS |
        * PREV2_CURR2_COUNT = | PREV_HAP2_READS intersection CURR_HAP2_READS |
        * PREV1_CURR2_COUNT = | PREV_HAP1_READS intersection CURR_HAP2_READS |
        * PREV2_CURR1_COUNT = | PREV_HAP2_READS intersection CURR_HAP1_READS |
        * ALL_READS_COUNT = | (PREV_HAP1_READS union PREV_HAP2_READS) intersection (CURR_HAP1_READS union CURR_HAP2_READS)
    1. Find ratio supporting overlap cases
        * We're trying to determine whether the previous Haplotype1 merges with the current Haplotype1 (and prev Hap2 with curr Hap2), or the previous Haplotype1 merges with the current Haplotype2 (and prev Hap2 with curr Hap1).  So in this step we count the total number of read overlaps which back up one of these, then then find the ratio of these as compared to all reads.
        * SAME_ORDER_COUNT = PREV1_CURR1_COUNT + PREV2_CURR2_COUNT
        * DIFF_ORDER_COUNT = PREV1_CURR2_COUNT + PREV1_CURR2_COUNT
        * SAME_ORDER_RATIO = SAME_ORDER_COUNT / ALL_READS_COUNT
        * DIFF_ORDER_RATIO = DIFF_ORDER_COUNT / ALL_READS_COUNT
    1. Recommend a merging strategy
        * Here we use the information from the previous step to recommend whether prev Hap1 merges with curr Hap1 (SAME_ORDERING), whether prev Hap1 merges with curr Hap2 (DIFF_ORDERING), or whether there is not enough evidence to support either (NO_MERGE).
        * if SAME_ORDER_RATIO >= MERGE_RATIO: recommend SAME_ORDERING
        * elif DIFF_ORDER_RATIO >= MERGE_RATIO: recommend DIFF_ORDERING
        * else: recommend NO_MERGE
    1. Handle merge:
        * if SAME_ORDERING or DIFF_ORDERING:
            * Append reads from each the chunk's haplotype SAM to the appropriate haplotype SAM for the current merge. Exclude reads which are in PREV_HAP1_READS or PREV_HAP2_READS
            * Append vcf calls from the chunks VCF to the VCF for the current merge.  Exclude calls which are not in the chunk boundary positions (without the margins).  If DIFF_ORDERING, reverse the phase.
        * if NO_MERGE
            * Create a new MergedHaplotype1, MergedHaplotype2, MergedVCF from the chunks Haplotype1, Haplotype2, and VCF (each new Merged file gets a new index when created)
        * Append all calls (within the chunk boundary positions) to the FullMergedVCF
    1. Iterate
        * PREV_HAP1_READS = {all read IDs which are between CHUNK_END-CHUNK_MARGIN and CHUNK_END+CHUNK_MARGIN for the chunks Haplotype1 SAM file}
        * PREV_HAP2_READS = {same, except for the chunk's Haplotype2 SAM file}

